Some weights of the model checkpoint at qarib/bert-base-qarib were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of the model checkpoint at qarib/bert-base-qarib were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of the model checkpoint at qarib/bert-base-qarib were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
675
3000
Training started with cuda
/home/aelmekki/.conda/envs/tabnet/lib/python3.7/site-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  FutureWarning,
/home/aelmekki/.local/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: DET seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/aelmekki/.local/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: NOUN seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/aelmekki/.local/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: NSUFF seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/aelmekki/.local/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: V seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/aelmekki/.local/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: PRON seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/aelmekki/.local/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ADJ seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/aelmekki/.local/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: CASE seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/aelmekki/.local/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: CONJ seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/aelmekki/.local/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: PREP seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/aelmekki/.local/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: PART seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/aelmekki/.local/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: PROG_PART seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/aelmekki/.local/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: PUNC seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/aelmekki/.local/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: HASH seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/aelmekki/.local/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: EMOT seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/aelmekki/.local/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: FUT_PART seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/aelmekki/.local/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: NEG_PART seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/aelmekki/.local/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: NUM seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/aelmekki/.local/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: MENTION seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/aelmekki/.local/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ADV seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/aelmekki/.local/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: URL seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/aelmekki/.local/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: FOREIGN seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/aelmekki/.local/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: WB seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))

##########     save the best model EGY.    #############

iter: 00500, Macro F1: 0.53097
iter: 00500, F1 EGY: 0.53097, best F1 for EGY: 0.53097

##########     save the best model GLF.    #############

iter: 00500, Macro F1: 0.66458
iter: 00500, F1 GLF: 0.66458, best F1 for GLF: 0.66458

##########     save the best model LEV.    #############

iter: 00500, Macro F1: 0.56301
iter: 00500, F1 LEV: 0.56301, best F1 for LEV: 0.56301

##########     save the best model MAG.    #############

iter: 00500, Macro F1: 0.56301
iter: 00500, F1 MAG: 0.53183, best F1 for MAG: 0.53183

##########     save the best model MSA.    #############

iter: 00500, Macro F1: 0.78485
iter: 00500, F1 MSA: 0.78485, best F1 for MSA: 0.78485
/home/aelmekki/.local/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ABBREV seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/aelmekki/.local/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: TB seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))

##########     save the best model EGY.    #############

iter: 01000, Macro F1: 0.53355
iter: 01000, F1 EGY: 0.53355, best F1 for EGY: 0.53355
iter: 01000, F1 GLF: 0.63313, best F1 for GLF: 0.66458

##########     save the best model LEV.    #############

iter: 01000, Macro F1: 0.56997
iter: 01000, F1 LEV: 0.56997, best F1 for LEV: 0.56997
iter: 01000, F1 MAG: 0.52721, best F1 for MAG: 0.53183

##########     save the best model MSA.    #############

iter: 01000, Macro F1: 0.86723
iter: 01000, F1 MSA: 0.86723, best F1 for MSA: 0.86723

##########     save the best model EGY.    #############

iter: 01500, Macro F1: 0.54473
iter: 01500, F1 EGY: 0.54473, best F1 for EGY: 0.54473

##########     save the best model GLF.    #############

iter: 01500, Macro F1: 0.67479
iter: 01500, F1 GLF: 0.67479, best F1 for GLF: 0.67479

##########     save the best model LEV.    #############

iter: 01500, Macro F1: 0.58256
iter: 01500, F1 LEV: 0.58256, best F1 for LEV: 0.58256
iter: 01500, F1 MAG: 0.50446, best F1 for MAG: 0.53183

##########     save the best model MSA.    #############

iter: 01500, Macro F1: 0.87938
iter: 01500, F1 MSA: 0.87938, best F1 for MSA: 0.87938
iter: 02000, F1 EGY: 0.54061, best F1 for EGY: 0.54473
iter: 02000, F1 GLF: 0.64361, best F1 for GLF: 0.67479
iter: 02000, F1 LEV: 0.55200, best F1 for LEV: 0.58256
iter: 02000, F1 MAG: 0.51015, best F1 for MAG: 0.53183
iter: 02000, F1 MSA: 0.87061, best F1 for MSA: 0.87938
iter: 02500, F1 EGY: 0.54052, best F1 for EGY: 0.54473
iter: 02500, F1 GLF: 0.66944, best F1 for GLF: 0.67479
iter: 02500, F1 LEV: 0.57423, best F1 for LEV: 0.58256
iter: 02500, F1 MAG: 0.49905, best F1 for MAG: 0.53183
iter: 02500, F1 MSA: 0.87141, best F1 for MSA: 0.87938
iter: 03000, F1 EGY: 0.54106, best F1 for EGY: 0.54473

##########     save the best model GLF.    #############

iter: 03000, Macro F1: 0.67662
iter: 03000, F1 GLF: 0.67662, best F1 for GLF: 0.67662
iter: 03000, F1 LEV: 0.57826, best F1 for LEV: 0.58256
iter: 03000, F1 MAG: 0.50005, best F1 for MAG: 0.53183
iter: 03000, F1 MSA: 0.87308, best F1 for MSA: 0.87938
iter: 03500, F1 EGY: 0.54296, best F1 for EGY: 0.54473
iter: 03500, F1 GLF: 0.67505, best F1 for GLF: 0.67662
iter: 03500, F1 LEV: 0.57091, best F1 for LEV: 0.58256
iter: 03500, F1 MAG: 0.50281, best F1 for MAG: 0.53183
iter: 03500, F1 MSA: 0.87274, best F1 for MSA: 0.87938
Some weights of the model checkpoint at qarib/bert-base-qarib were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of the model checkpoint at qarib/bert-base-qarib were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
0
Training started with cuda
/home/aelmekki/.local/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: U seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))

##########     save the best model EGY.    #############

iter: 00500, Macro F1: 0.55088
iter: 00500, F1 EGY: 0.55088, best F1 for EGY: 0.55088

##########     save the best model GLF.    #############

iter: 00500, Macro F1: 0.67977
iter: 00500, F1 GLF: 0.67977, best F1 for GLF: 0.67977
iter: 00500, F1 LEV: 0.58173, best F1 for LEV: 0.58256
iter: 00500, F1 MAG: 0.52944, best F1 for MAG: 0.53183
iter: 00500, F1 MSA: 0.87172, best F1 for MSA: 0.87938
iter: 01000, F1 EGY: 0.54900, best F1 for EGY: 0.55088

##########     save the best model GLF.    #############

iter: 01000, Macro F1: 0.68008
iter: 01000, F1 GLF: 0.68008, best F1 for GLF: 0.68008

##########     save the best model LEV.    #############

iter: 01000, Macro F1: 0.60734
iter: 01000, F1 LEV: 0.60734, best F1 for LEV: 0.60734
iter: 01000, F1 MAG: 0.51231, best F1 for MAG: 0.53183

##########     save the best model MSA.    #############

iter: 01000, Macro F1: 0.92672
iter: 01000, F1 MSA: 0.92672, best F1 for MSA: 0.92672

##########     save the best model EGY.    #############

iter: 01500, Macro F1: 0.55342
iter: 01500, F1 EGY: 0.55342, best F1 for EGY: 0.55342
iter: 01500, F1 GLF: 0.67148, best F1 for GLF: 0.68008

##########     save the best model LEV.    #############

iter: 01500, Macro F1: 0.62280
iter: 01500, F1 LEV: 0.62280, best F1 for LEV: 0.62280

##########     save the best model MAG.    #############

iter: 01500, Macro F1: 0.62280
iter: 01500, F1 MAG: 0.53659, best F1 for MAG: 0.53659

##########     save the best model MSA.    #############

iter: 01500, Macro F1: 0.92903
iter: 01500, F1 MSA: 0.92903, best F1 for MSA: 0.92903
iter: 02000, F1 EGY: 0.54692, best F1 for EGY: 0.55342
iter: 02000, F1 GLF: 0.67616, best F1 for GLF: 0.68008
iter: 02000, F1 LEV: 0.58625, best F1 for LEV: 0.62280
iter: 02000, F1 MAG: 0.51420, best F1 for MAG: 0.53659

##########     save the best model MSA.    #############

iter: 02000, Macro F1: 0.93068
iter: 02000, F1 MSA: 0.93068, best F1 for MSA: 0.93068

##########     save the best model EGY.    #############

iter: 02500, Macro F1: 0.55524
iter: 02500, F1 EGY: 0.55524, best F1 for EGY: 0.55524
iter: 02500, F1 GLF: 0.67392, best F1 for GLF: 0.68008
iter: 02500, F1 LEV: 0.58471, best F1 for LEV: 0.62280
iter: 02500, F1 MAG: 0.50411, best F1 for MAG: 0.53659
iter: 02500, F1 MSA: 0.92605, best F1 for MSA: 0.93068

##########     save the best model EGY.    #############

iter: 03000, Macro F1: 0.55745
iter: 03000, F1 EGY: 0.55745, best F1 for EGY: 0.55745
iter: 03000, F1 GLF: 0.67504, best F1 for GLF: 0.68008
iter: 03000, F1 LEV: 0.61803, best F1 for LEV: 0.62280
iter: 03000, F1 MAG: 0.51203, best F1 for MAG: 0.53659
iter: 03000, F1 MSA: 0.93017, best F1 for MSA: 0.93068
iter: 03500, F1 EGY: 0.55719, best F1 for EGY: 0.55745
iter: 03500, F1 GLF: 0.67999, best F1 for GLF: 0.68008
iter: 03500, F1 LEV: 0.61945, best F1 for LEV: 0.62280
iter: 03500, F1 MAG: 0.51950, best F1 for MAG: 0.53659
iter: 03500, F1 MSA: 0.91692, best F1 for MSA: 0.93068
Some weights of the model checkpoint at qarib/bert-base-qarib were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of the model checkpoint at qarib/bert-base-qarib were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
30649
Training started with cuda
iter: 00500, F1 EGY: 0.47994, best F1 for EGY: 0.55745
iter: 00500, F1 GLF: 0.60316, best F1 for GLF: 0.68008
iter: 00500, F1 LEV: 0.47784, best F1 for LEV: 0.62280
iter: 00500, F1 MAG: 0.41987, best F1 for MAG: 0.53659
iter: 00500, F1 MSA: 0.69098, best F1 for MSA: 0.93068
iter: 01000, F1 EGY: 0.52157, best F1 for EGY: 0.55745
iter: 01000, F1 GLF: 0.65115, best F1 for GLF: 0.68008
iter: 01000, F1 LEV: 0.57406, best F1 for LEV: 0.62280
iter: 01000, F1 MAG: 0.49092, best F1 for MAG: 0.53659
iter: 01000, F1 MSA: 0.73353, best F1 for MSA: 0.93068

##########     save the best model EGY.    #############

iter: 01500, Macro F1: 0.55789
iter: 01500, F1 EGY: 0.55789, best F1 for EGY: 0.55789
iter: 01500, F1 GLF: 0.67763, best F1 for GLF: 0.68008
iter: 01500, F1 LEV: 0.59038, best F1 for LEV: 0.62280

##########     save the best model MAG.    #############

iter: 01500, Macro F1: 0.62280
iter: 01500, F1 MAG: 0.53660, best F1 for MAG: 0.53660
iter: 01500, F1 MSA: 0.81475, best F1 for MSA: 0.93068
iter: 02000, F1 EGY: 0.55751, best F1 for EGY: 0.55789
iter: 02000, F1 GLF: 0.67788, best F1 for GLF: 0.68008
iter: 02000, F1 LEV: 0.58672, best F1 for LEV: 0.62280
iter: 02000, F1 MAG: 0.53059, best F1 for MAG: 0.53660
iter: 02000, F1 MSA: 0.91879, best F1 for MSA: 0.93068
iter: 02500, F1 EGY: 0.54855, best F1 for EGY: 0.55789
iter: 02500, F1 GLF: 0.67569, best F1 for GLF: 0.68008
iter: 02500, F1 LEV: 0.55927, best F1 for LEV: 0.62280
iter: 02500, F1 MAG: 0.52773, best F1 for MAG: 0.53660
iter: 02500, F1 MSA: 0.91392, best F1 for MSA: 0.93068
iter: 03000, F1 EGY: 0.55274, best F1 for EGY: 0.55789
iter: 03000, F1 GLF: 0.67641, best F1 for GLF: 0.68008
iter: 03000, F1 LEV: 0.59409, best F1 for LEV: 0.62280

##########     save the best model MAG.    #############

iter: 03000, Macro F1: 0.62280
iter: 03000, F1 MAG: 0.53820, best F1 for MAG: 0.53820
iter: 03000, F1 MSA: 0.92862, best F1 for MSA: 0.93068
iter: 03500, F1 EGY: 0.54768, best F1 for EGY: 0.55789
iter: 03500, F1 GLF: 0.67884, best F1 for GLF: 0.68008
iter: 03500, F1 LEV: 0.57994, best F1 for LEV: 0.62280
iter: 03500, F1 MAG: 0.50478, best F1 for MAG: 0.53820
iter: 03500, F1 MSA: 0.91733, best F1 for MSA: 0.93068

##########     save the best model EGY.    #############

iter: 04000, Macro F1: 0.56147
iter: 04000, F1 EGY: 0.56147, best F1 for EGY: 0.56147
iter: 04000, F1 GLF: 0.66611, best F1 for GLF: 0.68008
iter: 04000, F1 LEV: 0.55910, best F1 for LEV: 0.62280
iter: 04000, F1 MAG: 0.53207, best F1 for MAG: 0.53820
iter: 04000, F1 MSA: 0.91593, best F1 for MSA: 0.93068

##########     save the best model EGY.    #############

iter: 04500, Macro F1: 0.57272
iter: 04500, F1 EGY: 0.57272, best F1 for EGY: 0.57272

##########     save the best model GLF.    #############

iter: 04500, Macro F1: 0.68129
iter: 04500, F1 GLF: 0.68129, best F1 for GLF: 0.68129
iter: 04500, F1 LEV: 0.56969, best F1 for LEV: 0.62280
iter: 04500, F1 MAG: 0.51405, best F1 for MAG: 0.53820
iter: 04500, F1 MSA: 0.92623, best F1 for MSA: 0.93068
iter: 05000, F1 EGY: 0.56876, best F1 for EGY: 0.57272
iter: 05000, F1 GLF: 0.66629, best F1 for GLF: 0.68129
iter: 05000, F1 LEV: 0.55320, best F1 for LEV: 0.62280
iter: 05000, F1 MAG: 0.50593, best F1 for MAG: 0.53820
iter: 05000, F1 MSA: 0.87263, best F1 for MSA: 0.93068

##########     save the best model EGY.    #############

iter: 05500, Macro F1: 0.57312
iter: 05500, F1 EGY: 0.57312, best F1 for EGY: 0.57312
iter: 05500, F1 GLF: 0.66808, best F1 for GLF: 0.68129
iter: 05500, F1 LEV: 0.56567, best F1 for LEV: 0.62280
iter: 05500, F1 MAG: 0.52046, best F1 for MAG: 0.53820
iter: 05500, F1 MSA: 0.92985, best F1 for MSA: 0.93068
iter: 06000, F1 EGY: 0.55168, best F1 for EGY: 0.57312
iter: 06000, F1 GLF: 0.64759, best F1 for GLF: 0.68129
iter: 06000, F1 LEV: 0.54669, best F1 for LEV: 0.62280

##########     save the best model MAG.    #############

iter: 06000, Macro F1: 0.62280
iter: 06000, F1 MAG: 0.54598, best F1 for MAG: 0.54598
iter: 06000, F1 MSA: 0.92675, best F1 for MSA: 0.93068
iter: 06500, F1 EGY: 0.57296, best F1 for EGY: 0.57312

##########     save the best model GLF.    #############

iter: 06500, Macro F1: 0.68312
iter: 06500, F1 GLF: 0.68312, best F1 for GLF: 0.68312
iter: 06500, F1 LEV: 0.57312, best F1 for LEV: 0.62280
iter: 06500, F1 MAG: 0.52028, best F1 for MAG: 0.54598
iter: 06500, F1 MSA: 0.87588, best F1 for MSA: 0.93068
iter: 07000, F1 EGY: 0.55291, best F1 for EGY: 0.57312
iter: 07000, F1 GLF: 0.67122, best F1 for GLF: 0.68312
iter: 07000, F1 LEV: 0.58340, best F1 for LEV: 0.62280
iter: 07000, F1 MAG: 0.51427, best F1 for MAG: 0.54598
iter: 07000, F1 MSA: 0.91555, best F1 for MSA: 0.93068
iter: 07500, F1 EGY: 0.53472, best F1 for EGY: 0.57312
iter: 07500, F1 GLF: 0.63291, best F1 for GLF: 0.68312
iter: 07500, F1 LEV: 0.55571, best F1 for LEV: 0.62280

##########     save the best model MAG.    #############

iter: 07500, Macro F1: 0.62280
iter: 07500, F1 MAG: 0.55948, best F1 for MAG: 0.55948
iter: 07500, F1 MSA: 0.91691, best F1 for MSA: 0.93068
iter: 08000, F1 EGY: 0.54020, best F1 for EGY: 0.57312

##########     save the best model GLF.    #############

iter: 08000, Macro F1: 0.68397
iter: 08000, F1 GLF: 0.68397, best F1 for GLF: 0.68397
iter: 08000, F1 LEV: 0.57673, best F1 for LEV: 0.62280
iter: 08000, F1 MAG: 0.49897, best F1 for MAG: 0.55948
iter: 08000, F1 MSA: 0.87419, best F1 for MSA: 0.93068
iter: 08500, F1 EGY: 0.56719, best F1 for EGY: 0.57312
iter: 08500, F1 GLF: 0.67541, best F1 for GLF: 0.68397
iter: 08500, F1 LEV: 0.55477, best F1 for LEV: 0.62280
iter: 08500, F1 MAG: 0.51890, best F1 for MAG: 0.55948
iter: 08500, F1 MSA: 0.92419, best F1 for MSA: 0.93068
iter: 09000, F1 EGY: 0.56763, best F1 for EGY: 0.57312
iter: 09000, F1 GLF: 0.66554, best F1 for GLF: 0.68397
iter: 09000, F1 LEV: 0.55406, best F1 for LEV: 0.62280
iter: 09000, F1 MAG: 0.50857, best F1 for MAG: 0.55948
iter: 09000, F1 MSA: 0.92266, best F1 for MSA: 0.93068
iter: 09500, F1 EGY: 0.53724, best F1 for EGY: 0.57312
iter: 09500, F1 GLF: 0.65229, best F1 for GLF: 0.68397
iter: 09500, F1 LEV: 0.55280, best F1 for LEV: 0.62280
iter: 09500, F1 MAG: 0.51569, best F1 for MAG: 0.55948
iter: 09500, F1 MSA: 0.87188, best F1 for MSA: 0.93068
iter: 10000, F1 EGY: 0.55516, best F1 for EGY: 0.57312
iter: 10000, F1 GLF: 0.65319, best F1 for GLF: 0.68397
iter: 10000, F1 LEV: 0.52726, best F1 for LEV: 0.62280
iter: 10000, F1 MAG: 0.50662, best F1 for MAG: 0.55948
iter: 10000, F1 MSA: 0.92783, best F1 for MSA: 0.93068
iter: 10500, F1 EGY: 0.54592, best F1 for EGY: 0.57312
iter: 10500, F1 GLF: 0.67368, best F1 for GLF: 0.68397
iter: 10500, F1 LEV: 0.54836, best F1 for LEV: 0.62280
iter: 10500, F1 MAG: 0.50881, best F1 for MAG: 0.55948
iter: 10500, F1 MSA: 0.91140, best F1 for MSA: 0.93068

##########     save the best model EGY.    #############

iter: 11000, Macro F1: 0.61966
iter: 11000, F1 EGY: 0.61966, best F1 for EGY: 0.61966
iter: 11000, F1 GLF: 0.65516, best F1 for GLF: 0.68397
iter: 11000, F1 LEV: 0.54615, best F1 for LEV: 0.62280
iter: 11000, F1 MAG: 0.51450, best F1 for MAG: 0.55948
iter: 11000, F1 MSA: 0.86610, best F1 for MSA: 0.93068
iter: 11500, F1 EGY: 0.54952, best F1 for EGY: 0.61966
iter: 11500, F1 GLF: 0.66067, best F1 for GLF: 0.68397
iter: 11500, F1 LEV: 0.53710, best F1 for LEV: 0.62280
iter: 11500, F1 MAG: 0.51565, best F1 for MAG: 0.55948
iter: 11500, F1 MSA: 0.85944, best F1 for MSA: 0.93068
iter: 12000, F1 EGY: 0.55374, best F1 for EGY: 0.61966
iter: 12000, F1 GLF: 0.65645, best F1 for GLF: 0.68397
iter: 12000, F1 LEV: 0.55763, best F1 for LEV: 0.62280
iter: 12000, F1 MAG: 0.52894, best F1 for MAG: 0.55948
iter: 12000, F1 MSA: 0.88000, best F1 for MSA: 0.93068
iter: 12500, F1 EGY: 0.54210, best F1 for EGY: 0.61966
iter: 12500, F1 GLF: 0.65534, best F1 for GLF: 0.68397
iter: 12500, F1 LEV: 0.57493, best F1 for LEV: 0.62280
iter: 12500, F1 MAG: 0.51761, best F1 for MAG: 0.55948
iter: 12500, F1 MSA: 0.87455, best F1 for MSA: 0.93068
iter: 13000, F1 EGY: 0.54036, best F1 for EGY: 0.61966
iter: 13000, F1 GLF: 0.65922, best F1 for GLF: 0.68397
iter: 13000, F1 LEV: 0.57629, best F1 for LEV: 0.62280
iter: 13000, F1 MAG: 0.51191, best F1 for MAG: 0.55948
iter: 13000, F1 MSA: 0.87470, best F1 for MSA: 0.93068
iter: 13500, F1 EGY: 0.54138, best F1 for EGY: 0.61966
iter: 13500, F1 GLF: 0.67963, best F1 for GLF: 0.68397
iter: 13500, F1 LEV: 0.54799, best F1 for LEV: 0.62280
iter: 13500, F1 MAG: 0.52084, best F1 for MAG: 0.55948
iter: 13500, F1 MSA: 0.92360, best F1 for MSA: 0.93068
iter: 14000, F1 EGY: 0.56724, best F1 for EGY: 0.61966
iter: 14000, F1 GLF: 0.67516, best F1 for GLF: 0.68397
iter: 14000, F1 LEV: 0.54755, best F1 for LEV: 0.62280
iter: 14000, F1 MAG: 0.51518, best F1 for MAG: 0.55948
iter: 14000, F1 MSA: 0.82590, best F1 for MSA: 0.93068
iter: 14500, F1 EGY: 0.56896, best F1 for EGY: 0.61966

##########     save the best model GLF.    #############

iter: 14500, Macro F1: 0.68574
iter: 14500, F1 GLF: 0.68574, best F1 for GLF: 0.68574
iter: 14500, F1 LEV: 0.55182, best F1 for LEV: 0.62280
iter: 14500, F1 MAG: 0.51293, best F1 for MAG: 0.55948
iter: 14500, F1 MSA: 0.87318, best F1 for MSA: 0.93068
iter: 15000, F1 EGY: 0.56604, best F1 for EGY: 0.61966
iter: 15000, F1 GLF: 0.68224, best F1 for GLF: 0.68574
iter: 15000, F1 LEV: 0.55598, best F1 for LEV: 0.62280
iter: 15000, F1 MAG: 0.51292, best F1 for MAG: 0.55948
iter: 15000, F1 MSA: 0.92667, best F1 for MSA: 0.93068
iter: 15500, F1 EGY: 0.54265, best F1 for EGY: 0.61966
iter: 15500, F1 GLF: 0.65509, best F1 for GLF: 0.68574
iter: 15500, F1 LEV: 0.57767, best F1 for LEV: 0.62280
iter: 15500, F1 MAG: 0.52125, best F1 for MAG: 0.55948
iter: 15500, F1 MSA: 0.92485, best F1 for MSA: 0.93068
iter: 16000, F1 EGY: 0.61522, best F1 for EGY: 0.61966
iter: 16000, F1 GLF: 0.65494, best F1 for GLF: 0.68574
iter: 16000, F1 LEV: 0.55124, best F1 for LEV: 0.62280
iter: 16000, F1 MAG: 0.52334, best F1 for MAG: 0.55948
iter: 16000, F1 MSA: 0.92435, best F1 for MSA: 0.93068
iter: 16500, F1 EGY: 0.53897, best F1 for EGY: 0.61966
iter: 16500, F1 GLF: 0.66104, best F1 for GLF: 0.68574
iter: 16500, F1 LEV: 0.55658, best F1 for LEV: 0.62280
iter: 16500, F1 MAG: 0.51712, best F1 for MAG: 0.55948
iter: 16500, F1 MSA: 0.92251, best F1 for MSA: 0.93068
iter: 17000, F1 EGY: 0.60797, best F1 for EGY: 0.61966
iter: 17000, F1 GLF: 0.66479, best F1 for GLF: 0.68574
iter: 17000, F1 LEV: 0.55930, best F1 for LEV: 0.62280
iter: 17000, F1 MAG: 0.51693, best F1 for MAG: 0.55948
iter: 17000, F1 MSA: 0.92512, best F1 for MSA: 0.93068
iter: 17500, F1 EGY: 0.60827, best F1 for EGY: 0.61966
iter: 17500, F1 GLF: 0.66186, best F1 for GLF: 0.68574
iter: 17500, F1 LEV: 0.55359, best F1 for LEV: 0.62280
iter: 17500, F1 MAG: 0.51588, best F1 for MAG: 0.55948
iter: 17500, F1 MSA: 0.92278, best F1 for MSA: 0.93068
iter: 18000, F1 EGY: 0.61072, best F1 for EGY: 0.61966
iter: 18000, F1 GLF: 0.67205, best F1 for GLF: 0.68574
iter: 18000, F1 LEV: 0.55580, best F1 for LEV: 0.62280
iter: 18000, F1 MAG: 0.51689, best F1 for MAG: 0.55948
iter: 18000, F1 MSA: 0.87462, best F1 for MSA: 0.93068
iter: 18500, F1 EGY: 0.54827, best F1 for EGY: 0.61966
iter: 18500, F1 GLF: 0.65653, best F1 for GLF: 0.68574
iter: 18500, F1 LEV: 0.55773, best F1 for LEV: 0.62280
iter: 18500, F1 MAG: 0.50704, best F1 for MAG: 0.55948
iter: 18500, F1 MSA: 0.91798, best F1 for MSA: 0.93068
iter: 19000, F1 EGY: 0.54839, best F1 for EGY: 0.61966
iter: 19000, F1 GLF: 0.67886, best F1 for GLF: 0.68574
iter: 19000, F1 LEV: 0.55308, best F1 for LEV: 0.62280
iter: 19000, F1 MAG: 0.51105, best F1 for MAG: 0.55948
iter: 19000, F1 MSA: 0.92494, best F1 for MSA: 0.93068
iter: 19500, F1 EGY: 0.57069, best F1 for EGY: 0.61966
iter: 19500, F1 GLF: 0.67241, best F1 for GLF: 0.68574
iter: 19500, F1 LEV: 0.54478, best F1 for LEV: 0.62280
iter: 19500, F1 MAG: 0.51237, best F1 for MAG: 0.55948
iter: 19500, F1 MSA: 0.92362, best F1 for MSA: 0.93068
iter: 20000, F1 EGY: 0.61694, best F1 for EGY: 0.61966
iter: 20000, F1 GLF: 0.68376, best F1 for GLF: 0.68574
iter: 20000, F1 LEV: 0.53004, best F1 for LEV: 0.62280
iter: 20000, F1 MAG: 0.51454, best F1 for MAG: 0.55948
iter: 20000, F1 MSA: 0.87066, best F1 for MSA: 0.93068
iter: 20500, F1 EGY: 0.54592, best F1 for EGY: 0.61966
iter: 20500, F1 GLF: 0.68227, best F1 for GLF: 0.68574
iter: 20500, F1 LEV: 0.54762, best F1 for LEV: 0.62280
iter: 20500, F1 MAG: 0.50493, best F1 for MAG: 0.55948
iter: 20500, F1 MSA: 0.92277, best F1 for MSA: 0.93068
iter: 21000, F1 EGY: 0.53965, best F1 for EGY: 0.61966
iter: 21000, F1 GLF: 0.67929, best F1 for GLF: 0.68574
iter: 21000, F1 LEV: 0.54775, best F1 for LEV: 0.62280
iter: 21000, F1 MAG: 0.49911, best F1 for MAG: 0.55948
iter: 21000, F1 MSA: 0.87737, best F1 for MSA: 0.93068
iter: 21500, F1 EGY: 0.54317, best F1 for EGY: 0.61966
iter: 21500, F1 GLF: 0.67447, best F1 for GLF: 0.68574
iter: 21500, F1 LEV: 0.56042, best F1 for LEV: 0.62280
iter: 21500, F1 MAG: 0.50131, best F1 for MAG: 0.55948
iter: 21500, F1 MSA: 0.92639, best F1 for MSA: 0.93068
iter: 22000, F1 EGY: 0.54323, best F1 for EGY: 0.61966
iter: 22000, F1 GLF: 0.67447, best F1 for GLF: 0.68574
iter: 22000, F1 LEV: 0.56289, best F1 for LEV: 0.62280
iter: 22000, F1 MAG: 0.50019, best F1 for MAG: 0.55948
iter: 22000, F1 MSA: 0.92577, best F1 for MSA: 0.93068
iter: 22500, F1 EGY: 0.54191, best F1 for EGY: 0.61966
iter: 22500, F1 GLF: 0.68001, best F1 for GLF: 0.68574
iter: 22500, F1 LEV: 0.58543, best F1 for LEV: 0.62280
iter: 22500, F1 MAG: 0.50114, best F1 for MAG: 0.55948
iter: 22500, F1 MSA: 0.92163, best F1 for MSA: 0.93068
iter: 23000, F1 EGY: 0.55416, best F1 for EGY: 0.61966
iter: 23000, F1 GLF: 0.67683, best F1 for GLF: 0.68574
iter: 23000, F1 LEV: 0.55299, best F1 for LEV: 0.62280
iter: 23000, F1 MAG: 0.50304, best F1 for MAG: 0.55948
iter: 23000, F1 MSA: 0.82809, best F1 for MSA: 0.93068
iter: 23500, F1 EGY: 0.57520, best F1 for EGY: 0.61966
iter: 23500, F1 GLF: 0.67841, best F1 for GLF: 0.68574
iter: 23500, F1 LEV: 0.55421, best F1 for LEV: 0.62280
iter: 23500, F1 MAG: 0.50375, best F1 for MAG: 0.55948
iter: 23500, F1 MSA: 0.90999, best F1 for MSA: 0.93068
iter: 24000, F1 EGY: 0.57568, best F1 for EGY: 0.61966
iter: 24000, F1 GLF: 0.68428, best F1 for GLF: 0.68574
iter: 24000, F1 LEV: 0.53729, best F1 for LEV: 0.62280
iter: 24000, F1 MAG: 0.50533, best F1 for MAG: 0.55948
iter: 24000, F1 MSA: 0.90453, best F1 for MSA: 0.93068
iter: 24500, F1 EGY: 0.57495, best F1 for EGY: 0.61966
iter: 24500, F1 GLF: 0.68389, best F1 for GLF: 0.68574
iter: 24500, F1 LEV: 0.53885, best F1 for LEV: 0.62280
iter: 24500, F1 MAG: 0.50809, best F1 for MAG: 0.55948
iter: 24500, F1 MSA: 0.90399, best F1 for MSA: 0.93068
Some weights of the model checkpoint at qarib/bert-base-qarib were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of the model checkpoint at qarib/bert-base-qarib were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
iter: 25000, F1 EGY: 0.57797, best F1 for EGY: 0.61966
iter: 25000, F1 GLF: 0.67821, best F1 for GLF: 0.68574
iter: 25000, F1 LEV: 0.55471, best F1 for LEV: 0.62280
iter: 25000, F1 MAG: 0.49938, best F1 for MAG: 0.55948
iter: 25000, F1 MSA: 0.87219, best F1 for MSA: 0.93068
30661
Training started with cuda
/home/aelmekki/.local/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: EOS seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
iter: 00500, F1 EGY: 0.42417, best F1 for EGY: 0.61966
iter: 00500, F1 GLF: 0.55265, best F1 for GLF: 0.68574
iter: 00500, F1 LEV: 0.44832, best F1 for LEV: 0.62280
iter: 00500, F1 MAG: 0.43433, best F1 for MAG: 0.55948
iter: 00500, F1 MSA: 0.69697, best F1 for MSA: 0.93068
iter: 01000, F1 EGY: 0.56491, best F1 for EGY: 0.61966
iter: 01000, F1 GLF: 0.63722, best F1 for GLF: 0.68574
iter: 01000, F1 LEV: 0.52172, best F1 for LEV: 0.62280
iter: 01000, F1 MAG: 0.52391, best F1 for MAG: 0.55948
iter: 01000, F1 MSA: 0.75195, best F1 for MSA: 0.93068
iter: 01500, F1 EGY: 0.59360, best F1 for EGY: 0.61966
iter: 01500, F1 GLF: 0.67685, best F1 for GLF: 0.68574
iter: 01500, F1 LEV: 0.53198, best F1 for LEV: 0.62280
iter: 01500, F1 MAG: 0.53974, best F1 for MAG: 0.55948
iter: 01500, F1 MSA: 0.82424, best F1 for MSA: 0.93068

##########     save the best model EGY.    #############

iter: 02000, Macro F1: 0.64340
iter: 02000, F1 EGY: 0.64340, best F1 for EGY: 0.64340
iter: 02000, F1 GLF: 0.68168, best F1 for GLF: 0.68574
iter: 02000, F1 LEV: 0.51273, best F1 for LEV: 0.62280
iter: 02000, F1 MAG: 0.53763, best F1 for MAG: 0.55948
iter: 02000, F1 MSA: 0.82827, best F1 for MSA: 0.93068
iter: 02500, F1 EGY: 0.64086, best F1 for EGY: 0.64340

##########     save the best model GLF.    #############

iter: 02500, Macro F1: 0.69482
iter: 02500, F1 GLF: 0.69482, best F1 for GLF: 0.69482
iter: 02500, F1 LEV: 0.49248, best F1 for LEV: 0.62280
iter: 02500, F1 MAG: 0.51254, best F1 for MAG: 0.55948
iter: 02500, F1 MSA: 0.82331, best F1 for MSA: 0.93068
iter: 03000, F1 EGY: 0.63410, best F1 for EGY: 0.64340

##########     save the best model GLF.    #############

iter: 03000, Macro F1: 0.71274
iter: 03000, F1 GLF: 0.71274, best F1 for GLF: 0.71274
iter: 03000, F1 LEV: 0.50831, best F1 for LEV: 0.62280
iter: 03000, F1 MAG: 0.51142, best F1 for MAG: 0.55948
iter: 03000, F1 MSA: 0.83017, best F1 for MSA: 0.93068
iter: 03500, F1 EGY: 0.63453, best F1 for EGY: 0.64340
iter: 03500, F1 GLF: 0.70405, best F1 for GLF: 0.71274
iter: 03500, F1 LEV: 0.49775, best F1 for LEV: 0.62280
iter: 03500, F1 MAG: 0.51836, best F1 for MAG: 0.55948
iter: 03500, F1 MSA: 0.82536, best F1 for MSA: 0.93068
iter: 04000, F1 EGY: 0.62954, best F1 for EGY: 0.64340
iter: 04000, F1 GLF: 0.70597, best F1 for GLF: 0.71274
iter: 04000, F1 LEV: 0.51974, best F1 for LEV: 0.62280
iter: 04000, F1 MAG: 0.51907, best F1 for MAG: 0.55948
iter: 04000, F1 MSA: 0.82776, best F1 for MSA: 0.93068
iter: 04500, F1 EGY: 0.64060, best F1 for EGY: 0.64340
iter: 04500, F1 GLF: 0.70112, best F1 for GLF: 0.71274
iter: 04500, F1 LEV: 0.52449, best F1 for LEV: 0.62280
iter: 04500, F1 MAG: 0.51671, best F1 for MAG: 0.55948
iter: 04500, F1 MSA: 0.82407, best F1 for MSA: 0.93068
iter: 05000, F1 EGY: 0.63693, best F1 for EGY: 0.64340

##########     save the best model GLF.    #############

iter: 05000, Macro F1: 0.71401
iter: 05000, F1 GLF: 0.71401, best F1 for GLF: 0.71401
iter: 05000, F1 LEV: 0.53310, best F1 for LEV: 0.62280
iter: 05000, F1 MAG: 0.51814, best F1 for MAG: 0.55948
iter: 05000, F1 MSA: 0.81986, best F1 for MSA: 0.93068
iter: 05500, F1 EGY: 0.64110, best F1 for EGY: 0.64340

##########     save the best model GLF.    #############

iter: 05500, Macro F1: 0.71901
iter: 05500, F1 GLF: 0.71901, best F1 for GLF: 0.71901
iter: 05500, F1 LEV: 0.51345, best F1 for LEV: 0.62280
iter: 05500, F1 MAG: 0.50513, best F1 for MAG: 0.55948
iter: 05500, F1 MSA: 0.88220, best F1 for MSA: 0.93068
iter: 06000, F1 EGY: 0.63554, best F1 for EGY: 0.64340

##########     save the best model GLF.    #############

iter: 06000, Macro F1: 0.72536
iter: 06000, F1 GLF: 0.72536, best F1 for GLF: 0.72536
iter: 06000, F1 LEV: 0.51680, best F1 for LEV: 0.62280
iter: 06000, F1 MAG: 0.50763, best F1 for MAG: 0.55948
iter: 06000, F1 MSA: 0.81612, best F1 for MSA: 0.93068
iter: 06500, F1 EGY: 0.63361, best F1 for EGY: 0.64340
iter: 06500, F1 GLF: 0.70783, best F1 for GLF: 0.72536
iter: 06500, F1 LEV: 0.50585, best F1 for LEV: 0.62280
iter: 06500, F1 MAG: 0.50868, best F1 for MAG: 0.55948
iter: 06500, F1 MSA: 0.92381, best F1 for MSA: 0.93068
iter: 07000, F1 EGY: 0.63876, best F1 for EGY: 0.64340
iter: 07000, F1 GLF: 0.71577, best F1 for GLF: 0.72536
iter: 07000, F1 LEV: 0.51706, best F1 for LEV: 0.62280
iter: 07000, F1 MAG: 0.50811, best F1 for MAG: 0.55948
iter: 07000, F1 MSA: 0.92424, best F1 for MSA: 0.93068
iter: 07500, F1 EGY: 0.63742, best F1 for EGY: 0.64340
iter: 07500, F1 GLF: 0.72186, best F1 for GLF: 0.72536
iter: 07500, F1 LEV: 0.51903, best F1 for LEV: 0.62280
iter: 07500, F1 MAG: 0.51526, best F1 for MAG: 0.55948
iter: 07500, F1 MSA: 0.87339, best F1 for MSA: 0.93068
iter: 08000, F1 EGY: 0.63572, best F1 for EGY: 0.64340
iter: 08000, F1 GLF: 0.71385, best F1 for GLF: 0.72536
iter: 08000, F1 LEV: 0.52586, best F1 for LEV: 0.62280
iter: 08000, F1 MAG: 0.50756, best F1 for MAG: 0.55948
iter: 08000, F1 MSA: 0.92369, best F1 for MSA: 0.93068
iter: 08500, F1 EGY: 0.63708, best F1 for EGY: 0.64340
iter: 08500, F1 GLF: 0.71714, best F1 for GLF: 0.72536
iter: 08500, F1 LEV: 0.51322, best F1 for LEV: 0.62280
iter: 08500, F1 MAG: 0.51327, best F1 for MAG: 0.55948
iter: 08500, F1 MSA: 0.87415, best F1 for MSA: 0.93068
iter: 09000, F1 EGY: 0.63809, best F1 for EGY: 0.64340
iter: 09000, F1 GLF: 0.70817, best F1 for GLF: 0.72536
iter: 09000, F1 LEV: 0.52119, best F1 for LEV: 0.62280
iter: 09000, F1 MAG: 0.50496, best F1 for MAG: 0.55948
iter: 09000, F1 MSA: 0.82208, best F1 for MSA: 0.93068
iter: 09500, F1 EGY: 0.60624, best F1 for EGY: 0.64340
iter: 09500, F1 GLF: 0.68644, best F1 for GLF: 0.72536
iter: 09500, F1 LEV: 0.55562, best F1 for LEV: 0.62280
iter: 09500, F1 MAG: 0.47647, best F1 for MAG: 0.55948
iter: 09500, F1 MSA: 0.89451, best F1 for MSA: 0.93068
iter: 10000, F1 EGY: 0.56408, best F1 for EGY: 0.64340
iter: 10000, F1 GLF: 0.70244, best F1 for GLF: 0.72536
iter: 10000, F1 LEV: 0.52022, best F1 for LEV: 0.62280
iter: 10000, F1 MAG: 0.50698, best F1 for MAG: 0.55948
iter: 10000, F1 MSA: 0.92842, best F1 for MSA: 0.93068
iter: 10500, F1 EGY: 0.64272, best F1 for EGY: 0.64340
iter: 10500, F1 GLF: 0.70552, best F1 for GLF: 0.72536
iter: 10500, F1 LEV: 0.51274, best F1 for LEV: 0.62280
iter: 10500, F1 MAG: 0.51120, best F1 for MAG: 0.55948
iter: 10500, F1 MSA: 0.86650, best F1 for MSA: 0.93068
iter: 11000, F1 EGY: 0.64200, best F1 for EGY: 0.64340
iter: 11000, F1 GLF: 0.70340, best F1 for GLF: 0.72536
iter: 11000, F1 LEV: 0.51384, best F1 for LEV: 0.62280
iter: 11000, F1 MAG: 0.51199, best F1 for MAG: 0.55948
iter: 11000, F1 MSA: 0.92355, best F1 for MSA: 0.93068
iter: 11500, F1 EGY: 0.63829, best F1 for EGY: 0.64340
iter: 11500, F1 GLF: 0.65190, best F1 for GLF: 0.72536
iter: 11500, F1 LEV: 0.51269, best F1 for LEV: 0.62280
iter: 11500, F1 MAG: 0.48515, best F1 for MAG: 0.55948
iter: 11500, F1 MSA: 0.92469, best F1 for MSA: 0.93068
iter: 12000, F1 EGY: 0.63748, best F1 for EGY: 0.64340
iter: 12000, F1 GLF: 0.70208, best F1 for GLF: 0.72536
iter: 12000, F1 LEV: 0.51037, best F1 for LEV: 0.62280
iter: 12000, F1 MAG: 0.50809, best F1 for MAG: 0.55948
iter: 12000, F1 MSA: 0.87890, best F1 for MSA: 0.93068
iter: 12500, F1 EGY: 0.63484, best F1 for EGY: 0.64340
iter: 12500, F1 GLF: 0.69760, best F1 for GLF: 0.72536
iter: 12500, F1 LEV: 0.51552, best F1 for LEV: 0.62280
iter: 12500, F1 MAG: 0.50815, best F1 for MAG: 0.55948
iter: 12500, F1 MSA: 0.87860, best F1 for MSA: 0.93068
iter: 13000, F1 EGY: 0.62117, best F1 for EGY: 0.64340
iter: 13000, F1 GLF: 0.69681, best F1 for GLF: 0.72536
iter: 13000, F1 LEV: 0.51856, best F1 for LEV: 0.62280
iter: 13000, F1 MAG: 0.51271, best F1 for MAG: 0.55948
iter: 13000, F1 MSA: 0.82337, best F1 for MSA: 0.93068
iter: 13500, F1 EGY: 0.63260, best F1 for EGY: 0.64340
iter: 13500, F1 GLF: 0.70619, best F1 for GLF: 0.72536
iter: 13500, F1 LEV: 0.52485, best F1 for LEV: 0.62280
iter: 13500, F1 MAG: 0.50922, best F1 for MAG: 0.55948
iter: 13500, F1 MSA: 0.82583, best F1 for MSA: 0.93068
iter: 14000, F1 EGY: 0.55584, best F1 for EGY: 0.64340
iter: 14000, F1 GLF: 0.70183, best F1 for GLF: 0.72536
iter: 14000, F1 LEV: 0.52673, best F1 for LEV: 0.62280
iter: 14000, F1 MAG: 0.49922, best F1 for MAG: 0.55948
iter: 14000, F1 MSA: 0.86544, best F1 for MSA: 0.93068
iter: 14500, F1 EGY: 0.62907, best F1 for EGY: 0.64340
iter: 14500, F1 GLF: 0.65570, best F1 for GLF: 0.72536
iter: 14500, F1 LEV: 0.54051, best F1 for LEV: 0.62280
iter: 14500, F1 MAG: 0.53162, best F1 for MAG: 0.55948
iter: 14500, F1 MSA: 0.82448, best F1 for MSA: 0.93068
iter: 15000, F1 EGY: 0.63040, best F1 for EGY: 0.64340
iter: 15000, F1 GLF: 0.65893, best F1 for GLF: 0.72536
iter: 15000, F1 LEV: 0.51802, best F1 for LEV: 0.62280
iter: 15000, F1 MAG: 0.50258, best F1 for MAG: 0.55948
iter: 15000, F1 MSA: 0.82809, best F1 for MSA: 0.93068
iter: 15500, F1 EGY: 0.63113, best F1 for EGY: 0.64340
iter: 15500, F1 GLF: 0.65816, best F1 for GLF: 0.72536
iter: 15500, F1 LEV: 0.52117, best F1 for LEV: 0.62280
iter: 15500, F1 MAG: 0.50019, best F1 for MAG: 0.55948
iter: 15500, F1 MSA: 0.82670, best F1 for MSA: 0.93068
iter: 16000, F1 EGY: 0.63112, best F1 for EGY: 0.64340
iter: 16000, F1 GLF: 0.65281, best F1 for GLF: 0.72536
iter: 16000, F1 LEV: 0.53057, best F1 for LEV: 0.62280
iter: 16000, F1 MAG: 0.49887, best F1 for MAG: 0.55948
iter: 16000, F1 MSA: 0.82528, best F1 for MSA: 0.93068
Some weights of the model checkpoint at qarib/bert-base-qarib were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of the model checkpoint at qarib/bert-base-qarib were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
iter: 16500, F1 EGY: 0.63974, best F1 for EGY: 0.64340
iter: 16500, F1 GLF: 0.66430, best F1 for GLF: 0.72536
iter: 16500, F1 LEV: 0.53298, best F1 for LEV: 0.62280
iter: 16500, F1 MAG: 0.49549, best F1 for MAG: 0.55948
iter: 16500, F1 MSA: 0.82680, best F1 for MSA: 0.93068
30662
Training started with cuda
iter: 00500, F1 EGY: 0.48218, best F1 for EGY: 0.64340
iter: 00500, F1 GLF: 0.60110, best F1 for GLF: 0.72536
iter: 00500, F1 LEV: 0.45903, best F1 for LEV: 0.62280
iter: 00500, F1 MAG: 0.45717, best F1 for MAG: 0.55948
iter: 00500, F1 MSA: 0.72094, best F1 for MSA: 0.93068
iter: 01000, F1 EGY: 0.56064, best F1 for EGY: 0.64340
iter: 01000, F1 GLF: 0.62741, best F1 for GLF: 0.72536
iter: 01000, F1 LEV: 0.54875, best F1 for LEV: 0.62280
iter: 01000, F1 MAG: 0.52825, best F1 for MAG: 0.55948
iter: 01000, F1 MSA: 0.76801, best F1 for MSA: 0.93068
iter: 01500, F1 EGY: 0.57201, best F1 for EGY: 0.64340
iter: 01500, F1 GLF: 0.65425, best F1 for GLF: 0.72536
iter: 01500, F1 LEV: 0.55214, best F1 for LEV: 0.62280
iter: 01500, F1 MAG: 0.53020, best F1 for MAG: 0.55948
iter: 01500, F1 MSA: 0.82078, best F1 for MSA: 0.93068
iter: 02000, F1 EGY: 0.55671, best F1 for EGY: 0.64340
iter: 02000, F1 GLF: 0.64465, best F1 for GLF: 0.72536
iter: 02000, F1 LEV: 0.54704, best F1 for LEV: 0.62280
iter: 02000, F1 MAG: 0.50590, best F1 for MAG: 0.55948
iter: 02000, F1 MSA: 0.82377, best F1 for MSA: 0.93068
iter: 02500, F1 EGY: 0.57564, best F1 for EGY: 0.64340
iter: 02500, F1 GLF: 0.65565, best F1 for GLF: 0.72536
iter: 02500, F1 LEV: 0.54949, best F1 for LEV: 0.62280
iter: 02500, F1 MAG: 0.50240, best F1 for MAG: 0.55948
iter: 02500, F1 MSA: 0.82375, best F1 for MSA: 0.93068
iter: 03000, F1 EGY: 0.61969, best F1 for EGY: 0.64340
iter: 03000, F1 GLF: 0.65527, best F1 for GLF: 0.72536
iter: 03000, F1 LEV: 0.54743, best F1 for LEV: 0.62280
iter: 03000, F1 MAG: 0.50804, best F1 for MAG: 0.55948
iter: 03000, F1 MSA: 0.82197, best F1 for MSA: 0.93068
iter: 03500, F1 EGY: 0.63111, best F1 for EGY: 0.64340
iter: 03500, F1 GLF: 0.65606, best F1 for GLF: 0.72536
iter: 03500, F1 LEV: 0.58049, best F1 for LEV: 0.62280
iter: 03500, F1 MAG: 0.50422, best F1 for MAG: 0.55948
iter: 03500, F1 MSA: 0.87440, best F1 for MSA: 0.93068
iter: 04000, F1 EGY: 0.62721, best F1 for EGY: 0.64340
iter: 04000, F1 GLF: 0.67004, best F1 for GLF: 0.72536
iter: 04000, F1 LEV: 0.54697, best F1 for LEV: 0.62280
iter: 04000, F1 MAG: 0.50526, best F1 for MAG: 0.55948
iter: 04000, F1 MSA: 0.87210, best F1 for MSA: 0.93068
iter: 04500, F1 EGY: 0.55963, best F1 for EGY: 0.64340
iter: 04500, F1 GLF: 0.67288, best F1 for GLF: 0.72536
iter: 04500, F1 LEV: 0.54222, best F1 for LEV: 0.62280
iter: 04500, F1 MAG: 0.50783, best F1 for MAG: 0.55948
iter: 04500, F1 MSA: 0.81955, best F1 for MSA: 0.93068
iter: 05000, F1 EGY: 0.54408, best F1 for EGY: 0.64340
iter: 05000, F1 GLF: 0.66631, best F1 for GLF: 0.72536
iter: 05000, F1 LEV: 0.51106, best F1 for LEV: 0.62280
iter: 05000, F1 MAG: 0.50681, best F1 for MAG: 0.55948
iter: 05000, F1 MSA: 0.86566, best F1 for MSA: 0.93068
iter: 05500, F1 EGY: 0.53364, best F1 for EGY: 0.64340
iter: 05500, F1 GLF: 0.66205, best F1 for GLF: 0.72536
iter: 05500, F1 LEV: 0.50695, best F1 for LEV: 0.62280
iter: 05500, F1 MAG: 0.50256, best F1 for MAG: 0.55948
iter: 05500, F1 MSA: 0.86684, best F1 for MSA: 0.93068
iter: 06000, F1 EGY: 0.52482, best F1 for EGY: 0.64340
iter: 06000, F1 GLF: 0.65930, best F1 for GLF: 0.72536
iter: 06000, F1 LEV: 0.55059, best F1 for LEV: 0.62280
iter: 06000, F1 MAG: 0.50692, best F1 for MAG: 0.55948
iter: 06000, F1 MSA: 0.86864, best F1 for MSA: 0.93068
iter: 06500, F1 EGY: 0.52783, best F1 for EGY: 0.64340
iter: 06500, F1 GLF: 0.66792, best F1 for GLF: 0.72536
iter: 06500, F1 LEV: 0.51017, best F1 for LEV: 0.62280
iter: 06500, F1 MAG: 0.50696, best F1 for MAG: 0.55948
iter: 06500, F1 MSA: 0.86838, best F1 for MSA: 0.93068
iter: 07000, F1 EGY: 0.54821, best F1 for EGY: 0.64340
iter: 07000, F1 GLF: 0.66644, best F1 for GLF: 0.72536
iter: 07000, F1 LEV: 0.50196, best F1 for LEV: 0.62280
iter: 07000, F1 MAG: 0.50473, best F1 for MAG: 0.55948
iter: 07000, F1 MSA: 0.86767, best F1 for MSA: 0.93068
iter: 07500, F1 EGY: 0.51903, best F1 for EGY: 0.64340
iter: 07500, F1 GLF: 0.66841, best F1 for GLF: 0.72536
iter: 07500, F1 LEV: 0.50162, best F1 for LEV: 0.62280
iter: 07500, F1 MAG: 0.50184, best F1 for MAG: 0.55948
iter: 07500, F1 MSA: 0.86834, best F1 for MSA: 0.93068
iter: 08000, F1 EGY: 0.52940, best F1 for EGY: 0.64340
iter: 08000, F1 GLF: 0.67204, best F1 for GLF: 0.72536
iter: 08000, F1 LEV: 0.54914, best F1 for LEV: 0.62280
iter: 08000, F1 MAG: 0.50412, best F1 for MAG: 0.55948
iter: 08000, F1 MSA: 0.82883, best F1 for MSA: 0.93068
iter: 08500, F1 EGY: 0.53912, best F1 for EGY: 0.64340
iter: 08500, F1 GLF: 0.68486, best F1 for GLF: 0.72536
iter: 08500, F1 LEV: 0.53517, best F1 for LEV: 0.62280
iter: 08500, F1 MAG: 0.46555, best F1 for MAG: 0.55948
iter: 08500, F1 MSA: 0.86730, best F1 for MSA: 0.93068
iter: 09000, F1 EGY: 0.55948, best F1 for EGY: 0.64340
iter: 09000, F1 GLF: 0.65309, best F1 for GLF: 0.72536
iter: 09000, F1 LEV: 0.52369, best F1 for LEV: 0.62280
iter: 09000, F1 MAG: 0.50168, best F1 for MAG: 0.55948
iter: 09000, F1 MSA: 0.87358, best F1 for MSA: 0.93068
iter: 09500, F1 EGY: 0.55174, best F1 for EGY: 0.64340
iter: 09500, F1 GLF: 0.66096, best F1 for GLF: 0.72536
iter: 09500, F1 LEV: 0.54545, best F1 for LEV: 0.62280
iter: 09500, F1 MAG: 0.52034, best F1 for MAG: 0.55948
iter: 09500, F1 MSA: 0.88049, best F1 for MSA: 0.93068
iter: 10000, F1 EGY: 0.54204, best F1 for EGY: 0.64340
iter: 10000, F1 GLF: 0.66979, best F1 for GLF: 0.72536
iter: 10000, F1 LEV: 0.54593, best F1 for LEV: 0.62280
iter: 10000, F1 MAG: 0.50554, best F1 for MAG: 0.55948
iter: 10000, F1 MSA: 0.86150, best F1 for MSA: 0.93068
iter: 10500, F1 EGY: 0.54698, best F1 for EGY: 0.64340
iter: 10500, F1 GLF: 0.65413, best F1 for GLF: 0.72536
iter: 10500, F1 LEV: 0.52832, best F1 for LEV: 0.62280
iter: 10500, F1 MAG: 0.49617, best F1 for MAG: 0.55948
iter: 10500, F1 MSA: 0.84999, best F1 for MSA: 0.93068
--------------------------------------
Test on data/POS-tagging/egy
The final F1 on the Test set is 0.6208015373670397
The final accuracy on the Test set is 0.8208679593721145
--------------------------------------
Test on data/POS-tagging/glf
The final F1 on the Test set is 0.69424033588748
The final accuracy on the Test set is 0.8553800592300099
--------------------------------------
Test on data/POS-tagging/lev
The final F1 on the Test set is 0.575651356328113
The final accuracy on the Test set is 0.7773512476007678
--------------------------------------
Test on data/POS-tagging/mag
The final F1 on the Test set is 0.5447975838201182
The final accuracy on the Test set is 0.770896273917422
--------------------------------------
Test on data/POS-tagging/msa
The final F1 on the Test set is 0.8414993775525156
The final accuracy on the Test set is 0.9529983792544571
